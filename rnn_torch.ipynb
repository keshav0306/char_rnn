{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from load_data import *\n",
    "import numpy as np\n",
    "import time\n",
    "from rnn_layers_torch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, word_to_idx, wordvec_dim, hidden_dim, cell_type, seed):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        vocab_size = len(word_to_idx)\n",
    "        self.start_token = word_to_idx[\"<START>\"]\n",
    "        self.null_token = word_to_idx[\"<NULL>\"]\n",
    "        self.end_token = word_to_idx[\"<END>\"]\n",
    "        self.cell_type = cell_type\n",
    "        self.params = {}\n",
    "\n",
    "        if(seed is not None):\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        self.params[\"W_embed\"] = np.random.randn(vocab_size, wordvec_dim)\n",
    "        self.params[\"W_embed\"] /= 100\n",
    "\n",
    "        dim_mul = {\"lstm\": 4, \"rnn\": 1}[cell_type]\n",
    "        self.params[\"Wx\"] = np.random.randn(wordvec_dim, dim_mul * hidden_dim)\n",
    "        self.params[\"Wx\"] /= np.sqrt(wordvec_dim)\n",
    "        self.params[\"Wh\"] = np.random.randn(hidden_dim, dim_mul * hidden_dim)\n",
    "        self.params[\"Wh\"] /= np.sqrt(hidden_dim)\n",
    "        self.params[\"b\"] = np.zeros(dim_mul * hidden_dim)\n",
    "\n",
    "        self.params[\"W_vocab\"] = np.random.randn(hidden_dim, vocab_size)\n",
    "        self.params[\"W_vocab\"] /= np.sqrt(hidden_dim)\n",
    "        self.params[\"b_vocab\"] = np.zeros(vocab_size)\n",
    "\n",
    "        self.params[\"h_init\"] = np.random.randn(hidden_dim)\n",
    "\n",
    "        for key in self.params.keys():\n",
    "            self.params[key] = self.params[key].astype(np.float32)\n",
    "            self.params[key] = torch.from_numpy(self.params[key])\n",
    "            self.params[key].requires_grad = True\n",
    "\n",
    "\n",
    "        # self.params[\"W_embed\"] = torch.randn(vocab_size, wordvec_dim, requires_grad=True) / 100\n",
    "\n",
    "        # dim_mul = {\"lstm\": 4, \"rnn\": 1}[cell_type]\n",
    "        # self.params[\"Wx\"] = torch.randn(wordvec_dim, dim_mul * hidden_dim, requires_grad=True)\n",
    "        # self.params[\"Wh\"] = torch.randn(hidden_dim, dim_mul * hidden_dim,requires_grad=True)\n",
    "        # self.params[\"b\"] = torch.zeros(dim_mul * hidden_dim,requires_grad=True)\n",
    "        # self.params[\"W_vocab\"] = torch.randn(hidden_dim, vocab_size,requires_grad=True)\n",
    "        # self.params[\"b_vocab\"] = torch.zeros(vocab_size, requires_grad=True)\n",
    "        # self.params[\"h_init\"] = torch.randn(hidden_dim, requires_grad=True)\n",
    "\n",
    "    def forward(self, captions):\n",
    "\n",
    "        captions_out = captions[:,1:].clone()\n",
    "        captions_in = captions[:,:-1]\n",
    "        captions_out[:,0:8] = self.null_token\n",
    "        mask = captions_out != self.null_token\n",
    "        # print(captions_out)\n",
    "        # print(captions_in)\n",
    "        # print(mask)\n",
    "        N = captions.shape[0]\n",
    "        h0 = torch.tile(self.params[\"h_init\"], (N, 1))\n",
    "        h = None\n",
    "\n",
    "        inputs = word_embedding_forward(captions_in, self.params[\"W_embed\"])\n",
    "        if(self.cell_type == \"rnn\"):\n",
    "            h = rnn_forward(inputs, h0, self.params[\"Wx\"], self.params[\"Wh\"], self.params[\"b\"])\n",
    "        elif(self.cell_type == \"lstm\"):\n",
    "            h = lstm_forward(inputs, h0, self.params[\"Wx\"], self.params[\"Wh\"], self.params[\"b\"])\n",
    "        else:\n",
    "            return None\n",
    "        out = temporal_affine_forward(h, self.params[\"W_vocab\"], self.params[\"b_vocab\"])\n",
    "        loss = temporal_softmax_loss(out, captions_out, mask)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def load(self, params):\n",
    "        for key in self.params.keys():\n",
    "            self.params[key] = params[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'B',\n",
      " 1: 'N',\n",
      " 2: '3',\n",
      " 3: '0',\n",
      " 4: 's',\n",
      " 5: '4',\n",
      " 6: 'E',\n",
      " 7: 'P',\n",
      " 8: '\\n',\n",
      " 9: 'a',\n",
      " 10: '1',\n",
      " 11: '5',\n",
      " 12: '9',\n",
      " 13: '2',\n",
      " 14: '8',\n",
      " 15: '6',\n",
      " 16: '7',\n",
      " 17: '<START>',\n",
      " 18: '<NULL>',\n",
      " 19: '<END>'}\n"
     ]
    }
   ],
   "source": [
    "file_name = \"data/2_digit_ops.txt\"\n",
    "lwflag = 1 # 0 for words, 1 for letter\n",
    "word_to_idx = None\n",
    "\n",
    "if(lwflag):\n",
    "    word_to_idx = make_dict_letter(file_name)\n",
    "else:\n",
    "    word_to_idx = make_dict(file_name)\n",
    "reverse_dict = {}\n",
    "\n",
    "for keys, value in word_to_idx.items():\n",
    "    reverse_dict[value] = keys\n",
    "pprint(reverse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device(device)\n",
    "\n",
    "rnn = RNN(word_to_idx, 128, 128, \"lstm\", seed=7)\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "data = None\n",
    "# if(lwflag):\n",
    "#     data = load_data_letter(word_to_idx, file_name, lines_count=2, max_train=100)\n",
    "# else:\n",
    "#     data = load_data(word_to_idx, file_name, lines_count=1, max_train=4)\n",
    "data = load_data_letter_2_digit_ops(word_to_idx, file_name)\n",
    "data = torch.from_numpy(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'N', '1', '0', 's', 'N', '1', '3', 'E', 'B', 'P', '0', '3', 'E', '\\n']\n",
      "['B', 'N', '3', '3', 'a', 'N', '4', '8', 'E', 'B', 'N', '8', '1', 'E', '\\n']\n",
      "['B', 'N', '0', '8', 's', 'P', '3', '4', 'E', 'B', 'N', '4', '2', 'E', '\\n']\n",
      "['B', 'N', '3', '1', 's', 'N', '2', '7', 'E', 'B', 'N', '0', '4', 'E', '\\n']\n",
      "['B', 'N', '0', '5', 's', 'P', '2', '0', 'E', 'B', 'N', '2', '5', 'E', '\\n']\n",
      "['B', 'N', '3', '5', 's', 'N', '2', '6', 'E', 'B', 'N', '0', '9', 'E', '\\n']\n",
      "['B', 'N', '3', '0', 'a', 'P', '2', '4', 'E', 'B', 'N', '0', '6', 'E', '\\n']\n",
      "['B', 'N', '3', '3', 'a', 'N', '2', '4', 'E', 'B', 'N', '5', '7', 'E', '\\n']\n",
      "['B', 'N', '4', '5', 'a', 'N', '3', '7', 'E', 'B', 'N', '8', '2', 'E', '\\n']\n",
      "['B', 'N', '2', '1', 's', 'N', '2', '1', 'E', 'B', 'P', '0', '0', 'E', '\\n']\n",
      "['B', 'P', '0', '0', 'a', 'N', '0', '5', 'E', 'B', 'N', '0', '5', 'E', '\\n']\n",
      "['B', 'N', '1', '8', 'a', 'N', '3', '4', 'E', 'B', 'N', '5', '2', 'E', '\\n']\n",
      "['B', 'N', '2', '6', 's', 'P', '1', '5', 'E', 'B', 'N', '4', '1', 'E', '\\n']\n",
      "['B', 'P', '1', '1', 's', 'N', '1', '6', 'E', 'B', 'P', '2', '7', 'E', '\\n']\n",
      "['B', 'P', '1', '0', 'a', 'P', '1', '0', 'E', 'B', 'P', '2', '0', 'E', '\\n']\n",
      "['B', 'P', '4', '6', 's', 'P', '0', '3', 'E', 'B', 'P', '4', '3', 'E', '\\n']\n",
      "['B', 'N', '3', '9', 'a', 'P', '3', '4', 'E', 'B', 'N', '0', '5', 'E', '\\n']\n",
      "['B', 'P', '4', '6', 'a', 'N', '3', '7', 'E', 'B', 'P', '0', '9', 'E', '\\n']\n",
      "['B', 'N', '4', '2', 'a', 'N', '4', '5', 'E', 'B', 'N', '8', '7', 'E', '\\n']\n",
      "['B', 'P', '4', '9', 's', 'P', '4', '5', 'E', 'B', 'P', '0', '4', 'E', '\\n']\n",
      "['B', 'P', '3', '5', 's', 'N', '0', '9', 'E', 'B', 'P', '4', '4', 'E', '\\n']\n",
      "['B', 'P', '4', '1', 's', 'N', '1', '8', 'E', 'B', 'P', '5', '9', 'E', '\\n']\n",
      "['B', 'N', '0', '8', 'a', 'N', '4', '7', 'E', 'B', 'N', '5', '5', 'E', '\\n']\n",
      "['B', 'N', '0', '2', 'a', 'P', '1', '3', 'E', 'B', 'P', '1', '1', 'E', '\\n']\n",
      "['B', 'P', '0', '4', 's', 'N', '3', '1', 'E', 'B', 'P', '3', '5', 'E', '\\n']\n",
      "['B', 'N', '4', '9', 's', 'P', '1', '3', 'E', 'B', 'N', '6', '2', 'E', '\\n']\n",
      "['B', 'P', '4', '7', 'a', 'P', '1', '3', 'E', 'B', 'P', '6', '0', 'E', '\\n']\n",
      "['B', 'P', '1', '8', 's', 'N', '1', '7', 'E', 'B', 'P', '3', '5', 'E', '\\n']\n",
      "['B', 'N', '4', '3', 's', 'N', '0', '6', 'E', 'B', 'N', '3', '7', 'E', '\\n']\n",
      "['B', 'N', '2', '5', 's', 'P', '3', '4', 'E', 'B', 'N', '5', '9', 'E', '\\n']\n",
      "['B', 'P', '4', '6', 's', 'N', '3', '8', 'E', 'B', 'P', '8', '4', 'E', '\\n']\n",
      "['B', 'P', '4', '5', 'a', 'N', '4', '6', 'E', 'B', 'N', '0', '1', 'E', '\\n']\n",
      "['B', 'N', '4', '0', 'a', 'P', '4', '4', 'E', 'B', 'P', '0', '4', 'E', '\\n']\n",
      "['B', 'P', '2', '5', 's', 'P', '2', '2', 'E', 'B', 'P', '0', '3', 'E', '\\n']\n",
      "['B', 'P', '3', '8', 'a', 'P', '1', '8', 'E', 'B', 'P', '5', '6', 'E', '\\n']\n",
      "['B', 'N', '3', '3', 's', 'N', '2', '6', 'E', 'B', 'N', '0', '7', 'E', '\\n']\n",
      "['B', 'N', '3', '4', 'a', 'N', '1', '2', 'E', 'B', 'N', '4', '6', 'E', '\\n']\n",
      "['B', 'N', '1', '3', 'a', 'P', '2', '9', 'E', 'B', 'P', '1', '6', 'E', '\\n']\n",
      "['B', 'P', '3', '7', 'a', 'P', '3', '0', 'E', 'B', 'P', '6', '7', 'E', '\\n']\n",
      "['B', 'P', '0', '6', 'a', 'P', '2', '1', 'E', 'B', 'P', '2', '7', 'E', '\\n']\n",
      "['B', 'P', '3', '5', 'a', 'N', '2', '4', 'E', 'B', 'P', '1', '1', 'E', '\\n']\n",
      "['B', 'N', '1', '2', 'a', 'N', '2', '1', 'E', 'B', 'N', '3', '3', 'E', '\\n']\n",
      "['B', 'N', '1', '5', 's', 'P', '2', '4', 'E', 'B', 'N', '3', '9', 'E', '\\n']\n",
      "['B', 'N', '4', '3', 's', 'N', '4', '7', 'E', 'B', 'P', '0', '4', 'E', '\\n']\n",
      "['B', 'P', '3', '9', 's', 'P', '1', '7', 'E', 'B', 'P', '2', '2', 'E', '\\n']\n",
      "['B', 'N', '1', '2', 's', 'N', '2', '7', 'E', 'B', 'P', '1', '5', 'E', '\\n']\n",
      "['B', 'N', '4', '7', 's', 'P', '1', '7', 'E', 'B', 'N', '6', '4', 'E', '\\n']\n",
      "['B', 'P', '1', '0', 'a', 'N', '4', '8', 'E', 'B', 'N', '3', '8', 'E', '\\n']\n",
      "['B', 'N', '1', '8', 'a', 'N', '1', '4', 'E', 'B', 'N', '3', '2', 'E', '\\n']\n",
      "['B', 'N', '1', '2', 'a', 'N', '1', '6', 'E', 'B', 'N', '2', '8', 'E', '\\n']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    words = [reverse_dict[val.item()] for val in data[i]]\n",
    "    print((words))\n",
    "    # print(\"******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = torch.load(\"check.pt\", map_location=device)\n",
    "rnn.load(loaded[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.1830, grad_fn=<DivBackward0>)\n",
      "tensor(7.4691, grad_fn=<DivBackward0>)\n",
      "tensor(14.8676, grad_fn=<DivBackward0>)\n",
      "tensor(5.7286, grad_fn=<DivBackward0>)\n",
      "tensor(5.2638, grad_fn=<DivBackward0>)\n",
      "tensor(5.2113, grad_fn=<DivBackward0>)\n",
      "tensor(5.1934, grad_fn=<DivBackward0>)\n",
      "tensor(5.1833, grad_fn=<DivBackward0>)\n",
      "tensor(5.1734, grad_fn=<DivBackward0>)\n",
      "tensor(5.1671, grad_fn=<DivBackward0>)\n",
      "tensor(5.1623, grad_fn=<DivBackward0>)\n",
      "tensor(5.1476, grad_fn=<DivBackward0>)\n",
      "tensor(5.1411, grad_fn=<DivBackward0>)\n",
      "tensor(5.1372, grad_fn=<DivBackward0>)\n",
      "tensor(5.1343, grad_fn=<DivBackward0>)\n",
      "tensor(5.1589, grad_fn=<DivBackward0>)\n",
      "tensor(5.1515, grad_fn=<DivBackward0>)\n",
      "tensor(5.1485, grad_fn=<DivBackward0>)\n",
      "tensor(5.1464, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb Cell 7\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# words = [reverse_dict[val] for val in data[:].tolist()[1]]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# print(words)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss \u001b[39m=\u001b[39m rnn(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(loss)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m keys \u001b[39min\u001b[39;00m rnn\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mkeys():\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb Cell 7\u001b[0m in \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#W6sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     h \u001b[39m=\u001b[39m rnn_forward(inputs, h0, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mWx\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mWh\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#W6sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39melif\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcell_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlstm\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#W6sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     h \u001b[39m=\u001b[39m lstm_forward(inputs, h0, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams[\u001b[39m\"\u001b[39;49m\u001b[39mWx\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams[\u001b[39m\"\u001b[39;49m\u001b[39mWh\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams[\u001b[39m\"\u001b[39;49m\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#W6sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#W6sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/RNN/rnn_layers_torch.py:160\u001b[0m, in \u001b[0;36mlstm_forward\u001b[0;34m(x, h0, Wx, Wh, b)\u001b[0m\n\u001b[1;32m    157\u001b[0m h \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((N, T, H))\n\u001b[1;32m    159\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(T):\n\u001b[0;32m--> 160\u001b[0m     next_h, next_c \u001b[39m=\u001b[39m lstm_step_forward(x[:,i,:], prev_h, prev_c, Wx, Wh, b)\n\u001b[1;32m    161\u001b[0m     h[:,i,:] \u001b[39m=\u001b[39m next_h\n\u001b[1;32m    162\u001b[0m     prev_h \u001b[39m=\u001b[39m next_h\n",
      "File \u001b[0;32m~/Desktop/RNN/rnn_layers_torch.py:119\u001b[0m, in \u001b[0;36mlstm_step_forward\u001b[0;34m(x, prev_h, prev_c, Wx, Wh, b)\u001b[0m\n\u001b[1;32m    117\u001b[0m next_h, next_c \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    118\u001b[0m H \u001b[39m=\u001b[39m prev_h\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 119\u001b[0m a \u001b[39m=\u001b[39m x \u001b[39m@\u001b[39m Wx \u001b[39m+\u001b[39m prev_h \u001b[39m@\u001b[39;49m Wh \u001b[39m+\u001b[39m b \u001b[39m# (N * 4H)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39m# assume first H of a contain computations for input, next for forget, next for output, next for block \u001b[39;00m\n\u001b[1;32m    121\u001b[0m ai \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(a[:,:H])\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/torch/utils/_device.py:62\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m _device_constructors() \u001b[39mand\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\n\u001b[0;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters = []\n",
    "\n",
    "for key in rnn.params.keys():\n",
    "    parameters.append(rnn.params[key])\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.RMSprop(parameters, lr=learning_rate)\n",
    "# optimizer.load_state_dict(loaded[\"optime\"])\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # if(lwflag):\n",
    "    #     data = load_data_letter(word_to_idx, file_name, lines_count=1, max_train=100)\n",
    "    # else:\n",
    "    #     data = load_data(word_to_idx, file_name, lines_count=1, max_train=4)\n",
    "\n",
    "    data = load_data_letter_2_digit_ops(word_to_idx, file_name, max_train=3000)\n",
    "\n",
    "    data = torch.from_numpy(data)\n",
    "    # words = [reverse_dict[val] for val in data[:].tolist()[1]]\n",
    "    # print(words)\n",
    "    loss = rnn(data)\n",
    "    print(loss)\n",
    "    for keys in rnn.params.keys():\n",
    "        rnn.params[keys].retain_grad()\n",
    "    \n",
    "    optimizer.zero_grad()  # Clear gradients\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    # with torch.no_grad():\n",
    "    #     for key, value in rnn.params.items():\n",
    "    #         rnn.params[key] -= learning_rate * rnn.params[key].grad\n",
    "    #         rnn.params[key].grad.zero_()\n",
    "\n",
    "torch.save({\n",
    "    \"params\" : rnn.params,\n",
    "    \"optime\" : optimizer.state_dict()\n",
    "}, \"check.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The constituent of the sentence (either words or letters should be a part of word_to_dict)\n",
    "# Choose the words carefully!\n",
    "# torch.save({\n",
    "#     \"params\" : rnn.params,\n",
    "#     \"optime\" : optimizer.state_dict()\n",
    "# }, \"check.pt\")\n",
    "start_string = \"BN01sP04E\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = None\n",
    "num_len_start = None\n",
    "\n",
    "if(lwflag):\n",
    "    num_len_start = len(start_string)\n",
    "else:\n",
    "    words = start_string.split()\n",
    "    num_len_start = len(words)\n",
    "\n",
    "start_weights = rnn.params['W_embed'][rnn.start_token]\n",
    "start_weights = torch.tile(start_weights, (1, 1))\n",
    "\n",
    "prev_h = torch.tile(rnn.params[\"h_init\"], (1, 1))\n",
    "prev_c = torch.zeros((1, prev_h.shape[1]))\n",
    "curr_x = start_weights\n",
    "\n",
    "next_h, next_c = None, None\n",
    "max_length = 6\n",
    "captions = rnn.null_token * torch.ones((1, max_length + num_len_start), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_or_word = words\n",
    "if(lwflag):\n",
    "    letter_or_word = start_string\n",
    "    \n",
    "for i, letter in enumerate(letter_or_word):\n",
    "    if(rnn.cell_type == \"rnn\"):\n",
    "        next_h = rnn_step_forward(curr_x, prev_h, rnn.params[\"Wx\"], rnn.params[\"Wh\"], rnn.params[\"b\"])\n",
    "    else:\n",
    "        next_h, next_c = lstm_step_forward(curr_x, prev_h, prev_c, rnn.params[\"Wx\"], rnn.params[\"Wh\"], rnn.params[\"b\"])\n",
    "\n",
    "    out = affine_forward(next_h, rnn.params[\"W_vocab\"], rnn.params[\"b_vocab\"])\n",
    "    indices = torch.tensor(word_to_idx[letter])\n",
    "    captions[:, i] = indices\n",
    "    prev_h = next_h\n",
    "    prev_c = next_c\n",
    "    curr_x = rnn.params[\"W_embed\"][indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., nan, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "probability tensor contains either `inf`, `nan` or element < 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb Cell 11\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m out \u001b[39m=\u001b[39m out \u001b[39m/\u001b[39m torch\u001b[39m.\u001b[39msum(out, dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(out)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmultinomial(out, \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# print(indices)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# print(torch.argmax(out))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# print(out)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keshavgupta/Desktop/RNN/rnn_torch.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m captions[:, num_len_start \u001b[39m+\u001b[39m i] \u001b[39m=\u001b[39m indices\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.9/site-packages/torch/utils/_device.py:62\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39min\u001b[39;00m _device_constructors() \u001b[39mand\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\n\u001b[0;32m---> 62\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: probability tensor contains either `inf`, `nan` or element < 0"
     ]
    }
   ],
   "source": [
    "for i in range(max_length):\n",
    "    if(rnn.cell_type == \"rnn\"):\n",
    "        next_h = rnn_step_forward(curr_x, prev_h, rnn.params[\"Wx\"], rnn.params[\"Wh\"], rnn.params[\"b\"])\n",
    "    else:\n",
    "        next_h, next_c = lstm_step_forward(curr_x, prev_h, prev_c, rnn.params[\"Wx\"], rnn.params[\"Wh\"], rnn.params[\"b\"])\n",
    "        \n",
    "    out = affine_forward(next_h, rnn.params[\"W_vocab\"], rnn.params[\"b_vocab\"])\n",
    "    # indices = torch.argmax(out, dim=1)\n",
    "    # introduce temperature\n",
    "    # out = torch.softmax(out, dim = 1)\n",
    "    T = 0.31\n",
    "    out = torch.exp(out/T)\n",
    "    out = out / torch.sum(out, dim = 1)\n",
    "    print(out)\n",
    "    indices = torch.multinomial(out, 1).squeeze(0)\n",
    "    # print(indices)\n",
    "    # print(torch.argmax(out))\n",
    "    # print(out)\n",
    "    captions[:, num_len_start + i] = indices\n",
    "    prev_h = next_h\n",
    "    prev_c = next_c\n",
    "    curr_x = rnn.params[\"W_embed\"][indices]\n",
    "    # print(curr_x)\n",
    "\n",
    "captions = captions.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BN01sP04EBN07E\n",
      "\n",
      "******\n"
     ]
    }
   ],
   "source": [
    "file = open(\"out.txt\",'w')\n",
    "str = \"\"\n",
    "for i in range(len(captions)):\n",
    "    words = [reverse_dict[val] for val in captions[i]]\n",
    "    for letter in words:\n",
    "        str += letter\n",
    "    file.write(str)\n",
    "    print(str)\n",
    "    print(\"******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = np.array([ 6.0534e-01,  4.3694e+00,  2.8921e+00, -1.2803e+00, -4.4965e+00,\n",
    "         -1.2102e+00,  1.8877e+00,  4.4952e+00,  2.2088e+00, -4.9342e+00,\n",
    "          1.6454e+00,  2.4964e+00,  4.2149e+00, -3.4247e+00,  3.2256e+00,\n",
    "          3.7176e+00,  3.4167e+00, -1.7768e+00,  3.2877e+00, -3.4899e+00,\n",
    "          6.4797e-02, -2.9072e+00, -1.7842e+00,  4.1396e+00,  2.9905e+00,\n",
    "         -2.7464e+00, -1.3218e+00, -1.8224e+00, -3.8122e+00,  1.2878e+00,\n",
    "         -1.8629e+01, -8.8312e-01, -1.3546e+00, -3.0432e+00, -2.0706e+00,\n",
    "          4.2619e-01, -3.2271e+00, -2.8355e-01, -2.8540e+00,  1.6396e+00,\n",
    "          4.9245e+00,  2.5294e+00,  2.1570e+00, -3.9914e+00,  1.1421e+00,\n",
    "          2.2680e+00,  1.0391e+00, -1.9857e-02, -9.4496e+00, -1.4817e+01,\n",
    "          7.2657e-01, -1.0843e+01, -1.0294e+00, -1.3077e+01, -1.1968e+01,\n",
    "         -3.5006e+00, -2.9895e+00, -6.5954e-01, -1.5161e+01, -1.3209e+01,\n",
    "         -2.2323e+00, -1.1670e+01, -1.1378e+01, -1.5503e+01, -1.3931e+01,\n",
    "         -3.6289e+00, -9.6976e+00, -2.4147e+00,  1.2029e-01, -8.7026e+00,\n",
    "         -5.8831e+00, -5.3691e+00, -4.9089e+00, -1.7769e+00, -9.7471e+00,\n",
    "         -7.6364e+00, -1.7976e+01, -1.8692e+01, -7.2139e+00, -8.0258e+00,\n",
    "         -1.8363e+01, -1.1233e+01, -2.0220e+01, -2.0179e+01, -1.1242e+01])\n",
    "\n",
    "x = np.linspace(1,len(y), len(y))\n",
    "print(len(y))\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([ -0.9733,  10.8774,  10.0441,   4.4320,  -1.1357, -10.6907,  14.5207,\n",
    "          -2.8769,   9.4872,  -5.6361,  -0.6976, -16.2822,  11.1946, -14.1597,\n",
    "          -5.5444,   1.0754,  -5.3912,  -4.7569,   9.3502, -15.6364,  -2.4645,\n",
    "         -10.3533,  -5.3346,   9.6924,  -9.5424,  -9.7240,  -7.8794,  -6.6811,\n",
    "          -5.7003,   3.2312, -21.9670,  -6.1538,  -4.8924,  -9.5898,   0.1521,\n",
    "          -4.1660,  -4.6820,  -7.4905, -10.5066,  -6.9099,  -9.1708,  -2.5660,\n",
    "          -7.9966,  -5.9164,   8.7853,  -4.6198,  -9.4906,  -5.9581, -15.0839,\n",
    "         -19.0691,  -8.0916, -13.8294,  -4.2585, -12.2205, -17.0471, -15.0635,\n",
    "           4.9389,  -5.1173, -20.8669, -22.2936, -18.9036, -23.3794, -11.0086,\n",
    "         -21.8711, -14.2440,  -7.4616, -15.8068,  -4.7838,  -4.9030, -11.7466,\n",
    "          -3.5857,  -8.9297,  -5.9541, -10.3894, -12.4363, -10.7774, -21.1707,\n",
    "         -21.6002, -39.1100, -14.1335, -28.5526, -29.0288, -23.3054, -21.4974,\n",
    "         -25.8415])\n",
    "x = np.linspace(1,len(y), len(y))\n",
    "T = 100000\n",
    "plt.plot(x,np.exp(y/T) / np.sum(np.exp(y/T)))\n",
    "# plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(reverse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_before = [ 6.0534e-01,  4.3694e+00,  2.8921e+00, -1.2803e+00, -4.4965e+00,\n",
    "         -1.2102e+00,  1.8877e+00,  4.4952e+00,  2.2088e+00, -4.9342e+00,\n",
    "          1.6454e+00,  2.4964e+00,  4.2149e+00, -3.4247e+00,  3.2256e+00,\n",
    "          3.7176e+00,  3.4167e+00, -1.7768e+00,  3.2877e+00, -3.4899e+00,\n",
    "          6.4797e-02, -2.9072e+00, -1.7842e+00,  4.1396e+00,  2.9905e+00,\n",
    "         -2.7464e+00, -1.3218e+00, -1.8224e+00, -3.8122e+00,  1.2878e+00,\n",
    "         -1.8629e+01, -8.8312e-01, -1.3546e+00, -3.0432e+00, -2.0706e+00,\n",
    "          4.2619e-01, -3.2271e+00, -2.8355e-01, -2.8540e+00,  1.6396e+00,\n",
    "          4.9245e+00,  2.5294e+00,  2.1570e+00, -3.9914e+00,  1.1421e+00,\n",
    "          2.2680e+00,  1.0391e+00, -1.9857e-02, -9.4496e+00, -1.4817e+01,\n",
    "          7.2657e-01, -1.0843e+01, -1.0294e+00, -1.3077e+01, -1.1968e+01,\n",
    "         -3.5006e+00, -2.9895e+00, -6.5954e-01, -1.5161e+01, -1.3209e+01,\n",
    "         -2.2323e+00, -1.1670e+01, -1.1378e+01, -1.5503e+01, -1.3931e+01,\n",
    "         -3.6289e+00, -9.6976e+00, -2.4147e+00,  1.2029e-01, -8.7026e+00,\n",
    "         -5.8831e+00, -5.3691e+00, -4.9089e+00, -1.7769e+00, -9.7471e+00,\n",
    "         -7.6364e+00, -1.7976e+01, -1.8692e+01, -7.2139e+00, -8.0258e+00,\n",
    "         -1.8363e+01, -1.1233e+01, -2.0220e+01, -2.0179e+01, -1.1242e+01]\n",
    "\n",
    "t_before = [  0.8672,   4.2704,   1.6499,  -0.1441,  -5.4380,  -1.6326,   3.0245,\n",
    "           4.9084,   2.5126,  -4.8974,   1.4154,   3.2224,   2.7437,  -1.8678,\n",
    "           3.8421,   2.1870,   3.5555,  -1.7945,   3.5485,  -2.6484,   0.1289,\n",
    "          -2.8479,  -1.5428,   2.6185,   2.2913,  -3.0837,  -2.7430,  -0.9212,\n",
    "          -3.8082,   0.4127, -16.9907,  -1.0579,  -1.2042,  -1.7914,  -3.5872,\n",
    "          -1.0042,  -2.5655,  -2.1203,  -2.0782,   0.3144,   3.7498,   2.7011,\n",
    "           2.5335,  -4.2712,   2.8088,   2.2089,   0.9351,   0.5182,  -8.8479,\n",
    "         -12.8158,   1.9641, -10.5990,  -0.6618, -13.1240, -11.6949,  -2.3679,\n",
    "          -1.4294,  -2.0577, -14.6225, -13.6667,  -1.3513,  -8.3802,  -8.8191,\n",
    "         -14.4441, -13.4774,  -3.4689, -11.0212,  -1.7646,   0.3403,  -6.7329,\n",
    "          -6.3991,  -4.7024,  -4.1516,  -1.4665,  -8.4811,  -7.1091, -15.7866,\n",
    "         -16.2358,  -6.7877,  -7.1301, -17.4053, -10.6621, -19.3296, -19.2079,\n",
    "         -11.2567]\n",
    "\n",
    "after_e = [-1.0934e+01, -1.1948e+00,  4.4822e-02, -6.5232e-01,  7.9335e+00,\n",
    "         -8.2125e+00, -5.7796e+00,  1.6635e+00, -2.4267e+00, -2.9554e+00,\n",
    "          3.8696e+00,  2.9119e+00,  3.3425e+00, -9.7573e+00, -3.0463e+00,\n",
    "          2.1159e+00,  2.4975e+00, -1.6430e+01,  2.7373e+00, -2.0869e+01,\n",
    "          5.1378e+00, -1.4223e+01, -1.1924e+01, -2.9010e+00, -2.0186e+00,\n",
    "         -1.5791e+01, -1.1752e+01, -1.0855e+01, -2.0744e+01,  2.1554e+00,\n",
    "         -2.1378e+01, -6.1450e+00, -1.1220e+01, -4.8905e+00, -1.0900e+01,\n",
    "         -1.0639e+01, -9.7942e+00, -1.4185e+01, -1.4832e+01,  7.0777e-01,\n",
    "          2.2998e+00,  2.3042e-01,  6.2308e-03,  5.6740e+00, -5.1872e+00,\n",
    "          4.8951e+00, -5.6572e+00, -1.0699e+01, -1.6901e+01, -1.8379e+01,\n",
    "          6.3958e-01, -1.5640e+01, -1.0631e+01, -1.2981e+01, -1.7336e+01,\n",
    "         -1.3306e+01, -8.7787e-01,  1.2092e+00, -1.5528e+01, -1.8282e+01,\n",
    "         -1.5849e+01, -2.1366e+01, -1.3913e+00, -1.5046e+01, -1.4995e+01,\n",
    "         -1.1208e+01, -1.7130e+01, -1.6069e+00, -5.5352e+00, -3.9728e-01,\n",
    "          2.9421e+00,  1.9356e+00,  3.6271e+00, -1.6579e+01, -1.1398e+00,\n",
    "         -1.0887e+01, -2.5913e+01, -1.8709e+01, -3.9841e+01, -7.8933e+00,\n",
    "         -1.5357e+01, -2.5786e+01, -2.0423e+01, -1.9744e+01, -1.8157e+01]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
